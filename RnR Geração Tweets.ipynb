{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e0hYg-TQoQWK"
   },
   "source": [
    "# Exercício Geração Automática de Texto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tat3rdCEoQWM"
   },
   "source": [
    "Utilizando Redes Neurais Recorrentes(RNR) personalizei um modelo para a criação de tweets baseado em um datase no site kaggle com alguns tweets do Elon Musk, ou seja, dessa vez não utilizei para a predição mas sim para a geração."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0LirWGieoQWP"
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy\n",
    "import sys\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CZo15xSLIVjZ",
    "outputId": "12449b20-69a5-4f7d-a8bd-503cb52f1aa7"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "lqKZVvB0oQWQ"
   },
   "outputs": [],
   "source": [
    "\n",
    "filename = \"/content/drive/MyDrive/Colab Notebooks/RNR/data_elonmusk.txt\"\n",
    "raw_text = open(filename).read()\n",
    "raw_text = raw_text.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OmFxf6OdRtLB"
   },
   "outputs": [],
   "source": [
    "chars = sorted(list(set(raw_text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yCYuQ79koQWT",
    "outputId": "e00da5d8-7670-48f7-c212-e7bc8113b28c"
   },
   "outputs": [],
   "source": [
    "chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "9uuPg9_joQWS"
   },
   "outputs": [],
   "source": [
    "char_to_int = dict((c, i) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0LouBoNkoQWU",
    "outputId": "6b034ada-027e-44bc-de46-07128b4623a4"
   },
   "outputs": [],
   "source": [
    "char_to_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TYEk7t7_oQWU",
    "outputId": "1cbf6f56-db4e-49f4-9ea1-b21562c792bc"
   },
   "outputs": [],
   "source": [
    "n_chars = len(raw_text)\n",
    "n_vocab = len(chars)\n",
    "print (\"Total Characters: \", n_chars)\n",
    "print (\"Total Vocab: \", n_vocab)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q6SoL30LoQWW",
    "outputId": "a816a719-9fab-4c02-bc02-ad9db6827c46"
   },
   "outputs": [],
   "source": [
    "# À medida que dividimos o livro em sequências, convertemos os caracteres em números inteiros usando nossa\n",
    "# tabela de pesquisa que preparamos anteriormente.\n",
    "seq_length = 100\n",
    "dataX = []\n",
    "dataY = []\n",
    "\n",
    "for i in range(0, n_chars - seq_length, 1):\n",
    "    seq_in = raw_text[i:i + seq_length]\n",
    "    seq_out = raw_text[i + seq_length]\n",
    "    dataX.append([char_to_int[char] for char in seq_in])\n",
    "    dataY.append(char_to_int[seq_out])\n",
    "n_patterns = len(dataX)\n",
    "print (\"Total de Padrões: \", n_patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qeKrcX5gTeAG",
    "outputId": "fdcdac2d-5510-4e97-c302-619426c5e43a"
   },
   "outputs": [],
   "source": [
    "dataX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "ajsUO6SnoQWX"
   },
   "outputs": [],
   "source": [
    "# Reshape de X para [samples, time steps, features]\n",
    "X = numpy.reshape(dataX, (n_patterns, seq_length, 1))\n",
    "\n",
    "# Normalização\n",
    "X = X / float(n_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "4lB8nBGjoQWX"
   },
   "outputs": [],
   "source": [
    "# One-Hot Encoding da variável de saída\n",
    "y = np_utils.to_categorical(dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tGSFqevwVrno",
    "outputId": "657fc6b2-afd9-46a0-931a-dc12c0f54ff1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "thpLZ-3FoQWY"
   },
   "outputs": [],
   "source": [
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(256, input_shape=(X.shape[1], X.shape[2]), return_sequences=True))\n",
    "model.add(Dropout(0.35))\n",
    "model.add(LSTM(256))\n",
    "model.add(Dropout(0.35))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "fpgjRxYeoQWZ"
   },
   "outputs": [],
   "source": [
    "# Define o checkpoint\n",
    "filepath = \"weights-improvement-{epoch:02d}-{loss:.4f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor = 'loss', verbose = 1, save_best_only = True, mode = 'min')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "id": "uuOvYF7uoQWZ",
    "outputId": "45f5ac18-ce65-42f9-d30e-e4f458d7a9fa"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# model.fit(X, y, epochs = 20, batch_size = 128, callbacks = callbacks_list)\n",
    "model.fit(X, y, epochs = 3, batch_size = 256, callbacks = callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "AF4s6XhboQWa"
   },
   "outputs": [],
   "source": [
    "# Carrega os melhores pesos da rede e compila o modelo\n",
    "filename = \"/content/drive/MyDrive/Colab Notebooks/RNR/weights-improvement-03-1.5102.hdf5\"\n",
    "model.load_weights(filename)\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer = 'adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "fTBtjXiPoQWa"
   },
   "outputs": [],
   "source": [
    "int_to_char = dict((i, c) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GMIo6uuSoQWa",
    "outputId": "00d90ac7-bc0f-4ff2-f40a-aa61f3b82dfb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\" rbx impact\n",
      "       velocity and center of mass 2016-\n",
      "       of colliding object make a big 10-10\n",
      "row1 \"\n",
      "161hotps://t.co/xlallyzmm              03:33:33               elonmusk\n",
      "                             \n",
      "Concluído.\n"
     ]
    }
   ],
   "source": [
    "# Obtém um random seed\n",
    "start = numpy.random.randint(0, len(dataX)-1)\n",
    "\n",
    "# Inicia a geração de texto de um ponto qualquer, definido pelo random seed \"start\"\n",
    "pattern = dataX[start]\n",
    "print (\"\\\"\", ''.join([int_to_char[value] for value in pattern]), \"\\\"\")\n",
    "\n",
    "# Gerando caracteres\n",
    "for i in range(100):\n",
    "    x = numpy.reshape(pattern, (1, len(pattern), 1))\n",
    "    x = x / float(n_vocab)\n",
    "    prediction = model.predict(x, verbose=0)\n",
    "    index = numpy.argmax(prediction)\n",
    "    result = int_to_char[index]\n",
    "    seq_in = [int_to_char[value] for value in pattern]\n",
    "    sys.stdout.write(result)\n",
    "    pattern.append(index)\n",
    "    pattern = pattern[1:len(pattern)]\n",
    "print (\"\\nConcluído.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
